{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Train model with SageMaker</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create a Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from time import strftime, gmtime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set a sagemaker role  \n",
    "try:\n",
    "    # if you are on a sagemaker notebook instance\n",
    "    import sagemaker\n",
    "    role = sagemaker.get_execution_role()\n",
    "except: \n",
    "    # if locally, create a Sagemaker execution role in the aws console and assign it here\n",
    "    iam = boto3.client('iam')\n",
    "    role_name = \"YOUR_EXECUTIONROLE_FOR_SAGEMAKER\"\n",
    "    role = iam.get_role(RoleName=role_name)['Role']['Arn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using a local notabook, please make sure to modify `role_name` by a proper value. <br>\n",
    "For more details about roles, please sign in to [AWS Management Console](https://console.aws.amazon.com/iam/) and create a role in the left navigation pane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name # get the region name\n",
    "account = boto3.Session().client('sts').get_caller_identity()['Account'] # get the account id\n",
    "sm = boto3.Session().client('sagemaker') # create a sagemaker session\n",
    "print(\"role: {}\".format(role))\n",
    "print(\"region: {}\".format(region))\n",
    "print(\"account: {}\".format(account))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify the data and model location** <br>\n",
    "Please change the parameters in the following cells according to the location of your data and where you want to store the model artefacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data location\n",
    "bucket_name = \"sm-transformers-datasets\" # Bucket name where the data is located\n",
    "train_prefix = \"data/dataset_multilabel_500\" # folder of train data\n",
    "models_prefix = \"models\" # folder where model will be saved\n",
    "train_s3_uri = \"s3://{}/{}\".format(bucket_name, train_prefix)\n",
    "models_s3_uri = \"s3://{}/{}\".format(bucket_name, models_prefix)\n",
    "print(\"Train data location : {}\".format(train_s3_uri))\n",
    "print(\"Models data location : {}\".format(models_s3_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify the docker image name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = \"sm-transformers-gpu\"\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, image_name)\n",
    "print(\"image of model: {}\".format(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the training job name**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to explicitly set the training job name, ignore the following cell and change the value of `training_job_name` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training job name \n",
    "training_job_name = \"{}-{}\".format(image_name, strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()))\n",
    "# shorten it (should be less than 63 characters)\n",
    "if len(training_job_name) > 63:\n",
    "    training_job_name = training_job_name[max(len(training_job_name)-62,0):]\n",
    "print(\"training job name : {}\".format(training_job_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set checkpoints path**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally: You can specify an old training job name to be resumed !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_s3_uri = \"s3://{}/{}/{}/checkpoints\".format(bucket_name, models_prefix, training_job_name) #old_training_job\n",
    "print(\"checkpoints will be saved in {}\".format(checkpoints_s3_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Metrics to follow during training (by parsing the logs!)\n",
    "metrics = [\n",
    "            {\n",
    "            \"Name\": \"training:epoch\",\n",
    "            \"Regex\": \"'epoch': (.*?)}\"\n",
    "            },\n",
    "            {\n",
    "            \"Name\": \"evaluation:loss\",\n",
    "            \"Regex\": \"'eval_loss': (.*?),\"\n",
    "            },\n",
    "            {\n",
    "            \"Name\": \"evaluation:accuracy\",\n",
    "            \"Regex\": \"'eval_accuracy': (.*?),\" # eval_mse(regression), eval_accuracy (classif), eval_accuracy_score(ner)\n",
    "            }\n",
    "        ]\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can adjust the hyperparametrs of the model/expand them. <br>\n",
    "For example, you can decrease batch size if you have OOM errors, increase/decrease the max sequence length, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List of hyperparameters during training (optional)\n",
    "hyperparameters = {\n",
    "    \"task_name\": \"multilabel-classif\",\n",
    "    \"model_name\": \"bert-base-uncased\",\n",
    "    \"max_steps\": \"1000\",\n",
    "    \"use_bbox\": \"false\",\n",
    "    \"per_device_train_batch_size\": \"10\",\n",
    "    \"per_device_eval_batch_size\": \"10\"\n",
    "}\n",
    "#allenai/longformer-base-4096\n",
    "#bert-base-uncased\n",
    "#microsoft/layoutlm-base-uncased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick an instance type for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU : ml.g4dn.xlarge (ml.g4dn.xlarge   cpu:4     gpu:1xT4     cpu-ram:16    gpu-ram:16         training/hour$0.822)\n",
    "## classif: \n",
    "# bert : batch = 10 is ok (with text > 512) (70% GPU RAM busy)\n",
    "# Longformer: batch = 2 ok if text size after tokenization is < 2048 / batch 1: ok till limit! (4096) (89% GPU RAM utilised)\n",
    "\n",
    "## Token classif (ner)\n",
    "# bert: batch 10 is ok (with text > 512) (70% GPU RAM busy)\n",
    "# longformer: idem classif : batch = 2 ok if text size after tokenization is < 2048 / batch 1: ok till limit! (4096) (89% GPU RAM utilised)\n",
    "# layoutlm: batch 10 same than bert : is ok (with text > 512) (70% GPU RAM busy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List of GPU instance to be chosen\n",
    "#name            CPUs   GPU     RAM  GPU-RAM  TrainingPrice/hour\n",
    "#ml.p3.2xlarge    8    1xV100    61    16         $4.627         \n",
    "#ml.p2.xlarge     4     1xK80    61    12         $1.361\n",
    "#ml.g4dn.xlarge   4     1xT4     16    16         $0.822\n",
    "#ml.g4dn.2xlarge  8     1xT4     32    16         $1.173  <-\n",
    "#ml.g4dn.4xlarge  16    1xT4     64    16         $1.879\n",
    "#ml.g4dn.8xlarge  32    1xT4     128   16         $3.396\n",
    "#ml.g4dn.12xlarge 48    4xT4     192   64         $6.107\n",
    "#ml.g4dn.16xlarge 64    1xT4     256   16         $6.794\n",
    "\n",
    "instance_type = \"ml.g4dn.xlarge\" # \"ml.c4.4xlarge\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify some additional parameters for the training job:\n",
    "- Training image\n",
    "- Arn Role\n",
    "- Model Location\n",
    "- Instance type for the training job\n",
    "- Data config:\n",
    "    - Location for the training data (and potentially test data if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cpu: ml.c4.4xlarge (16 cpus)\n",
    "\n",
    "common_training_params = \\\n",
    "{\n",
    "    \"TrainingJobName\": training_job_name,\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": image,\n",
    "        \"TrainingInputMode\": \"File\",\n",
    "        \"MetricDefinitions\" : metrics\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": models_s3_uri\n",
    "    },\n",
    "    \"TensorBoardOutputConfig\": { \n",
    "      #\"LocalPath\": \"/opt/ml/output/tensorboard\", #default value is /opt/ml/output/tensorboard\n",
    "      \"S3OutputPath\": models_s3_uri\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 1,   \n",
    "        \"InstanceType\": instance_type,\n",
    "        \"VolumeSizeInGB\": 60\n",
    "    },\n",
    "    \"HyperParameters\": hyperparameters,\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 86400,\n",
    "        \"MaxWaitTimeInSeconds\": 86400\n",
    "    },\n",
    "    \"EnableManagedSpotTraining\": True,\n",
    "    \"CheckpointConfig\": { \n",
    "      #\"LocalPath\": \"/opt/ml/checkpoints/\", #default value is /opt/ml/checkpoints/\n",
    "      \"S3Uri\": checkpoints_s3_uri\n",
    "   },\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": train_s3_uri,\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\" \n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"text/plain\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(json.dumps(common_training_params, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a training job**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sm.create_training_job(**common_training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# monitor the training job\n",
    "status = sm.describe_training_job(TrainingJobName=training_job_name)['TrainingJobStatus']\n",
    "print(status)\n",
    "\n",
    "sm.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=training_job_name)\n",
    "status = sm.describe_training_job(TrainingJobName=training_job_name)['TrainingJobStatus']\n",
    "print(\"Training job ended with status: \" + status)\n",
    "if status == 'Failed':\n",
    "    message = sm.describe_training_job(TrainingJobName=training_job_name)['FailureReason']\n",
    "    print('Training failed with the following error: {}'.format(message))\n",
    "    raise Exception('Training job failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a model from Training Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training is finished, we can get the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_job_name = \"ner-bert-base-cased-gpu-2020-06-29-09-09-18\"\n",
    "print(training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** that you can specify a different docker image for inference than the one used for the training. <br>\n",
    "In our case, if we want to use `CPU` instead of `GPU` resources in the inference step, we can set it explicitely by changing the image variable value. In our case: <br>\n",
    "`image_name = \"classif-bert-base-uncased-cpu\"\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, image_name)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Uncomment if you want to use the CPU based image for Creating the model #####\n",
    "\n",
    "#image_name = \"classif-bert-base-multilingual-cased-cpu\"\n",
    "#image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, image_name)\n",
    "\n",
    "######################################  End ########################################\n",
    "\n",
    "\n",
    "# set the model name\n",
    "model_name = training_job_name + '-m'\n",
    "print(\"model_name : {}\".format(model_name))\n",
    "\n",
    "# get model artifacts location\n",
    "info = sm.describe_training_job(TrainingJobName=training_job_name)\n",
    "model_data = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(\"model_data : {}\".format(model_data))\n",
    "    \n",
    "primary_container = {\n",
    "    'Image': image,\n",
    "    'ModelDataUrl': model_data\n",
    "}\n",
    "print(\"primary_container : {}\".format(primary_container))\n",
    "\n",
    "# Create model\n",
    "create_model_response = sm.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
